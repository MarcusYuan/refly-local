# .env_llm_models.yaml.example - OpenAI 兼容 LLM 模型端点配置示例
# !!! 警告: 请勿在此文件中存储真实的 API Key !!!
# !!! 真实的 API Key 应存储在 .env_llm_models.yaml 文件中，并确保该文件已添加到 .gitignore !!!

endpoints:
  - name: "openrouter_example" # 端点名称，供内部识别
    # !!! 使用环境变量或安全的方式管理 API Key，不要直接写在这里 !!!
    api_key: "sk-or-replace-with-your-openrouter-key" # 示例 Key，请替换
    base_url: "https://openrouter.ai/api/v1"
    # 此端点支持的模型列表 (必须是 OpenAI 兼容的)
    models:
      - "openai/gpt-4-turbo"
      - "anthropic/claude-3-opus-20240229" # 通过 OpenRouter 访问
      - "google/gemini-pro"             # 通过 OpenRouter 访问
    # configuration: # 可选的额外配置, 会传递给 ChatDeepSeek (最终是 ChatOpenAI) 的 configuration
    #   defaultHeaders:
    #     'HTTP-Referer': 'https://your-app-url.com' # 替换为你的应用 URL
    #     'X-Title': 'YourAppName' # 替换为你的应用名称
    #   # 其他 ChatOpenAI 支持的 configuration 选项...

  - name: "openai_direct_example"
    api_key: "sk-replace-with-your-openai-key" # 示例 Key，请替换
    # base_url: "https://api.openai.com/v1" # 可选，如果需要覆盖 ChatDeepSeek 默认或 ChatOpenAI 默认
    models:
      - "gpt-4-turbo"
      - "gpt-3.5-turbo"
    # configuration: {} # 可选

  - name: "deepseek_direct_example"
    api_key: "sk-replace-with-your-deepseek-key" # 示例 Key，请替换
    # base_url: "https://api.deepseek.com" # 可选，ChatDeepSeek 默认会用这个
    models:
      - "deepseek-chat"
      - "deepseek-coder"
    # configuration: {} # 可选

# 可以继续添加更多 OpenAI 兼容的端点示例...
# 注意：不再需要 class_name 字段